{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "How can web scraping be used to extract data from websites?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KfeYcMI9YB_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many tools and techniques to extarct data from websites, there are more complex method using BeautifulSoup, Scrapy etc. like libraries and also there exist more convinent and easy to use interface tools such as webhook, webscraper etc. for more complex extraction seleium and other tools are also available."
      ],
      "metadata": {
        "id": "lo_QviDZp_4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can regular expressions be used in data cleaning?\n"
      ],
      "metadata": {
        "id": "eZyaQpTIYE3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expressions are set of wide variety of special caharcters which assist in text and special charcters extraction, matching, validating etc. though it has very wide appication in various environments. But it is very widely used in webscraping to extract specific kind of information."
      ],
      "metadata": {
        "id": "fJW4ZA1Mqngy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some common challenges in web scraping?\n"
      ],
      "metadata": {
        "id": "8BpXpxF6YGUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many challenges in web scraping, but given below are most frequently faced challenges :\n",
        "\n",
        "=> Not every website allow scraping / crawling.\n",
        "\n",
        "=> Scraping data from restricted websites is illegal.\n",
        "\n",
        "=> Extarcting very specifc info can be complex in  code.\n",
        "\n",
        "=> Drilling down through texts, links, hyperlinks and multiple pages requires complex logic building.\n",
        "\n",
        "=> Extracting clean information is challenging.\n",
        "\n",
        "=> Finding the source of data is very difficult."
      ],
      "metadata": {
        "id": "8hE-ifu1rXmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is data cleaning and why is it important?\n"
      ],
      "metadata": {
        "id": "5UOpdQ0pYIBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning involves many steps such as :\n",
        "\n",
        "=> Sorting the data\n",
        "\n",
        "=> Data Foramtting\n",
        "\n",
        "=> Data ambiguity.\n",
        "\n",
        "=> Handling missing values.\n",
        "\n",
        "=> Handling extreme data points.\n",
        "\n",
        "Data claening is important because, uncleaned or unstructured data may lead to misleading insights, or it can also make the data uninterpretable and if we are building some model on that data then model might be giving some horondus output. Also, data cleaning improves data accuracy, enhances data quality, and ensures consistency."
      ],
      "metadata": {
        "id": "eXt8EzqpsXW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some common issues that can arise when working with data?\n"
      ],
      "metadata": {
        "id": "o0OVKMm1YJXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Common issues are :\n",
        "\n",
        "=> Data type / Data Format\n",
        "\n",
        "=> Outliers in data\n",
        "\n",
        "=> Data distribution.\n",
        "\n",
        "=> Missing Data.\n",
        "\n",
        "=> Data ambiguity.\n",
        "\n",
        "=> Duplicate data.\n",
        "\n"
      ],
      "metadata": {
        "id": "sRuOYDP8tP2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some popular data formats for storing scraped data?\n"
      ],
      "metadata": {
        "id": "6qjBkU0cYKnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some popular data formats for storing scraped data :\n",
        "\n",
        "=> Text / String / Char.\n",
        "\n",
        "=> Tabular / DataFrame / Series\n",
        "\n",
        "=> Bulletin\n",
        "\n",
        "=> Numeric / int / float\n",
        "\n",
        "=> Encoded / Decoded"
      ],
      "metadata": {
        "id": "GMkgJFVKtseV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can data be transformed into a usable format?\n"
      ],
      "metadata": {
        "id": "MbSdYZCrYL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some common machine learning problems that involve data cleaning?\n"
      ],
      "metadata": {
        "id": "CfZZw2H7YNce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every ML model understand numeric / boolean data. Therefore Datatype is the first thing which need to be worked on. High variance in data points also leads to decrease in model accuracy, therefore noramaliztion / standardiztion is doen whn needed. Also categorical data need to be encoded."
      ],
      "metadata": {
        "id": "9QTURbFWuFhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is data integration and why is it important?\n"
      ],
      "metadata": {
        "id": "MZISVMX4YO4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main objective of data integration is to combine and consolidate data from a wide range of sources into one coherent form"
      ],
      "metadata": {
        "id": "rJ1R7Pqewo4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can missing data be dealt with in a dataset?\n"
      ],
      "metadata": {
        "id": "6MkQ-rvNYQZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many techniques to handle missing values such as :\n",
        "\n",
        "=> fillna()\n",
        "\n",
        "=> interpolate()\n",
        "\n",
        "=> SimpleImputer()\n",
        "\n",
        "=> replace()\n",
        "\n",
        "=> List comprehension\n",
        "\n",
        "=> apply()\n",
        "\n",
        "=> np.where()"
      ],
      "metadata": {
        "id": "Nyu1uC80uwM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some common methods for handling duplicate data?\n"
      ],
      "metadata": {
        "id": "VCeh7xUeYRjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many techniques to handle dupplicate values such as :\n",
        "\n",
        "=> duplicated()\n",
        "\n",
        "=> drop_duplicate()\n",
        "\n",
        "=> coditional programming\n",
        "\n",
        "=> List Comprehension\n",
        "\n"
      ],
      "metadata": {
        "id": "CzpyvnTpvFp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some sources of data that can be used for web scraping?"
      ],
      "metadata": {
        "id": "s-0N5bFmYSzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many sources where data scraping is allowed like :\n",
        "\n",
        "=> Wikipedia.\n",
        "\n",
        "=> Common crawl\n",
        "\n",
        "=> Yahoo Finance\n",
        "\n",
        "=> Google Search."
      ],
      "metadata": {
        "id": "X2khPOe0vkCL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqE3hZZHX_wF"
      },
      "outputs": [],
      "source": []
    }
  ]
}